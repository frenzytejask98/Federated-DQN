[DEFAULT]
# Flags for defining the tf.train.ClusterSpec
# Comma-separated list of hostname:port pairs
ps_hosts = localhost:13337
;worker_hosts = localhost:13338
;worker_hosts = localhost:13338,localhost:13339
;worker_hosts = localhost:13338,localhost:13339,localhost:13340
worker_hosts = localhost:13338,localhost:13339,localhost:13340,localhost:13341
;worker_hosts = localhost:13338,localhost:13339,localhost:13340,localhost:13341,localhost:13342
# 6 workers
;worker_hosts = localhost:13338,localhost:13339,localhost:13340,localhost:13341,localhost:13342,localhost:13343
# 8 workers
;worker_hosts = localhost:13338,localhost:13339,localhost:13340,localhost:13341,localhost:13342,localhost:13343,localhost:13344,localhost:13345
# 10 workers
;worker_hosts = localhost:13338,localhost:13339,localhost:13340,localhost:13341,localhost:13342,localhost:13343,localhost:13344,localhost:13345,localhost:13346,localhost:13347

# Flags for the Q-learning hyperparameters
# Learning rate for Adam optimizer
learning_rate = 5e-4
# Size of the sample used for the mini-batch fed to every learning step
batch_size = 32
# Max size of the experience replay memory
memory_size = 50000
# Local timesteps between updates to the target Q-network
target_update = 1000

# Flags for FedAvg algorithm hyperparameters
# Seed for randomness (reproducibility)
seed = 1
# Total number of communication rounds to execute before interrupting
comm_rounds = 100000
# Number of epochs to run every communication round (from the start)
start_epoch = 100
# Number of epochs to run every communication round (after epoch_decay rounds)
end_epoch = 80
# Linearly decay number of epochs from start_epoch to end_epoch over epoch_decay rounds
epoch_decay = 500
# Number of backup workers to use (implicitly sets n = total - b)
backup = 0
# Wether to use the synchronous or asynchronous version of the algorithm
sync = False
# Wether to use gradient prioritizing (own reward / reward sum)
gradient_prio = False

# Other flags
# If muted, output is reduced
mute = False

[async]
;learning_rate = 5e-3
;memory_size = 10000
target_update = 600
start_epoch = 50
end_epoch = 20
epoch_decay = 600
;comm_rounds = 30
comm_rounds = 30000000
seed = 30

[sync]
batch_size = 32
target_update = 300
backup = 0
comm_rounds = 1000000000
start_epoch = 1
end_epoch = 1
sync = True
gradient_prio = True